{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzoZX9kWhYh2"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/jkanclerz/dbs/blob/main/11--spark.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsMik6LdhcyC"
      },
      "source": [
        "## Instalacja Spark "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_vdHTQ1hXxY",
        "outputId": "dd795e9e-99b1-4907-daae-bfb7c51298a9"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz -O spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLapOJSlipVb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Ix9VcxtWzi",
        "outputId": "0bb11d9d-a651-417f-b416-2e55bbfcc06e"
      },
      "outputs": [],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0dzhAwXtSHk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "        .master(\"local\")\n",
        "        .appName(\"Spark playground\")\n",
        "        .getOrCreate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "4LkYrCSptoAg",
        "outputId": "416569eb-db48-4b0d-cb5d-62a4a86bc3a1"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpecdPYguXjM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHxpDKeXuX7h",
        "outputId": "da836e15-303b-4543-c1a9-ef301668b284"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvxHZnwItpPF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "schema = StructType([\n",
        "    StructField('Datetime', TimestampType()),\n",
        "    StructField('Open', DecimalType(), True),\n",
        "    StructField('High', DecimalType(), True),\n",
        "    StructField('Low', DecimalType(), True),\n",
        "    StructField('Close', DecimalType(), True),\n",
        "    StructField('Volume', IntegerType(), True),\n",
        "    StructField('Dividends', DoubleType(), True),\n",
        "    StructField('Stock Splits', DoubleType(), True)\n",
        "])\n",
        "df = (spark.read\n",
        "      .option(\"header\", True)\n",
        "      .option(\"recursiveFileLookup\", True)\n",
        "      .option(\"delimiter\", ',')\n",
        "      .schema(schema)\n",
        "      .csv('/content/drive/MyDrive/fo'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHJ6FHevwHF",
        "outputId": "d19ff4ac-7916-4b4a-8689-db4e8bf0abd5"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lV6hICywriI",
        "outputId": "6f8bf720-bb37-48df-9e4f-b5d10956db5a"
      },
      "outputs": [],
      "source": [
        "df.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAy4Ob23wvPf"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView('stocks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gyOpiwFyQki"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYeE8ZEDw0MI"
      },
      "outputs": [],
      "source": [
        "stocks = spark.sql('''\n",
        "  select \n",
        "    regexp_replace(input_file_name(), '.*([A-Z]{3}\\.WA).*', '$1') as ticker,\n",
        "    from_utc_timestamp(DateTime, 'Europe/Warsaw') datetime,\n",
        "    to_date(DateTime) as date,\n",
        "    Open open,\n",
        "    High high,\n",
        "    Close close,\n",
        "    Volume volume\n",
        "    from stocks limit \n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2QOfjp4zJuK"
      },
      "outputs": [],
      "source": [
        "(stocks.write\n",
        "  .option('overwrite', True)\n",
        "  .partitionBy(['ticker', 'date']).parquet(\"/content/drive/MyDrive/fo/stocks\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE0Hwd5g1A3w"
      },
      "outputs": [],
      "source": [
        "loadedDf = spark.read.parquet(\"/content/drive/MyDrive/fo/stocks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyyfYhfI1G7a",
        "outputId": "a138fd96-05d7-415c-9a0c-e33f39d95079"
      },
      "outputs": [],
      "source": [
        "loadedDf.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pstDOs2c1J5m",
        "outputId": "50831cfd-05ec-416a-c342-e4c50e271257"
      },
      "outputs": [],
      "source": [
        "loadedDf.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFVNn812Rdx",
        "outputId": "a2f23b49-0261-4a80-bd55-f11dfd48c84e"
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydi0Xzc12UWV"
      },
      "outputs": [],
      "source": [
        "loadedDf.createOrReplaceTempView('stocks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dJ1YjhN2ZBV",
        "outputId": "abb94d08-9068-4e18-b9c9-531c9c0d85aa"
      },
      "outputs": [],
      "source": [
        "spark.sql('''\n",
        "  with ranked as (\n",
        "  select\n",
        "    ticker,\n",
        "    datetime,\n",
        "    date, \n",
        "    close, \n",
        "    rank() over (partition by date order by datetime DESC) as rank\n",
        "  from stocks\n",
        "  where ticker = \"PKN.WA\"\n",
        "  order by datetime DESC)\n",
        "  \n",
        "  select * from ranked where rank = 1\n",
        "  ''').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01jB5xmd58p8"
      },
      "outputs": [],
      "source": [
        "asPd = spark.sql('''\n",
        "  with ranked as (\n",
        "  select\n",
        "    ticker,\n",
        "    datetime,\n",
        "    date, \n",
        "    close, \n",
        "    rank() over (partition by date order by datetime DESC) as rank\n",
        "  from stocks\n",
        "  where ticker = \"PKN.WA\"\n",
        "  order by datetime DESC)\n",
        "  \n",
        "  select date, cast (close as float) from ranked where rank = 1\n",
        "  ''').toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "n2uV4gTr7r5f",
        "outputId": "5d5a05a3-444b-41c5-a976-7b735946f93b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [16, 5]\n",
        "asPd.set_index('date').plot.line()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgtrgk6p-iLT"
      },
      "outputs": [],
      "source": [
        "toModelAll = spark.sql('''\n",
        "  select\n",
        "    ticker,\n",
        "    from_utc_timestamp(datetime, 'Europe/Warsaw') datetime,\n",
        "    date, \n",
        "    close,\n",
        "    lag(close, 1) over (order by datetime) lag_close_1,\n",
        "    lag(close, 2) over (order by datetime) lag_close_2,\n",
        "    lag(close, 3) over (order by datetime) lag_close_3,\n",
        "    lag(close, 4) over (order by datetime) lag_close_4,\n",
        "    lag(close, 5) over (order by datetime) lag_close_5,\n",
        "    volume,\n",
        "    lag(volume, 1) over (order by datetime) lag_volume_1,\n",
        "    lag(volume, 2) over (order by datetime) lag_volume_2,\n",
        "    lag(volume, 3) over (order by datetime) lag_volume_3,\n",
        "    lag(volume, 4) over (order by datetime) lag_volume_4,\n",
        "    lag(volume, 5) over (order by datetime) lag_volume_5\n",
        "  from stocks\n",
        "  where ticker = \"PKN.WA\" and date_format(from_utc_timestamp(datetime, 'Europe/Warsaw'), 'HH:mm:ss') >= \"09:00:00\" and date_format(from_utc_timestamp(datetime, 'Europe/Warsaw'), 'HH:mm:ss') < \"17:00:00\"\n",
        "  order by datetime DESC\n",
        "''').drop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO0j9wWA-mdp",
        "outputId": "3aa783b5-1c7f-43a8-bdd0-2985554925ca"
      },
      "outputs": [],
      "source": [
        "toModelAll.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2s8xbnhBzBZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXALjbjWB_AE"
      },
      "source": [
        "# Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abt1DQupCAVP"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEs4c1NhCCMn"
      },
      "outputs": [],
      "source": [
        "va = VectorAssembler(inputCols = ['lag_close_1', 'lag_close_2','lag_close_3','lag_close_4','lag_close_5','lag_volume_1','lag_volume_2','lag_volume_3','lag_volume_4','lag_volume_5'], outputCol = 'features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB9iiRK-DOXs",
        "outputId": "c3283995-8333-493b-d88a-beb2a68efd33"
      },
      "outputs": [],
      "source": [
        "toModelAll.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AccHIAihDxTG"
      },
      "outputs": [],
      "source": [
        "toModelAll = toModelAll.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je_0o_7bCTCO"
      },
      "outputs": [],
      "source": [
        "reg_df = va.transform(toModelAll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sghmh5wvCVlJ",
        "outputId": "9b58f676-9e71-4e89-ff7a-3747c942c8ee"
      },
      "outputs": [],
      "source": [
        "reg_df.select('features', 'close').show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghqmpq6sCqHr"
      },
      "source": [
        "https://spark.apache.org/docs/latest/ml-classification-regression.html https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMKN5ydiCpVa"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx7fGKyBC83s",
        "outputId": "b0a0e413-a1dc-4d8b-9ae5-9760e1bd56cd"
      },
      "outputs": [],
      "source": [
        "reg_df.select('features', 'close').printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpcTEMHBCpZ-"
      },
      "outputs": [],
      "source": [
        "(train_df, test_df) = reg_df.randomSplit([0.7, 0.3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaQZXYlGDfwZ",
        "outputId": "bf0b1f6c-ee00-45b1-f722-b970409054cb"
      },
      "outputs": [],
      "source": [
        "train_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdBz4QD5DdH4"
      },
      "outputs": [],
      "source": [
        " \n",
        "lr = LinearRegression(featuresCol='features',labelCol='close')\n",
        " \n",
        "lr_model = lr.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdpDeh2HCkY2",
        "outputId": "ccf55018-bcf2-4913-c138-c675fd0116a7"
      },
      "outputs": [],
      "source": [
        "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
        "print(\"Intercept: \" + str(lr_model.intercept))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn1APRnMFF-h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVqBWh8wFKrG"
      },
      "source": [
        "\n",
        "$$ \\hat{Y} = X_{1}{\\beta}_{1} + ... + X_{n}{\\beta}_{n} + {\\beta}_0 $$\n",
        "$$ \\hat{Y} = 0.6196 * X_{1} + ... + X_{n}{\\beta}_{n} + 0.293 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSdOw4hwFLD0"
      },
      "outputs": [],
      "source": [
        "trainingSummary = lr_model.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80DBz7N9F34a",
        "outputId": "ab900077-9c0a-488d-a415-3fd4fe26022a"
      },
      "outputs": [],
      "source": [
        "print(\"R2: %f\" % trainingSummary.r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ILGW95RF6wP"
      },
      "outputs": [],
      "source": [
        "lr_predictions = lr_model.transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3ccyp_xGDaN",
        "outputId": "22234edc-54ac-4897-844b-2917367315e1"
      },
      "outputs": [],
      "source": [
        "lr_predictions.select(\"prediction\",\"close\",\"features\").show(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbp8vGClGIyW"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMZ2ewOyGVoO",
        "outputId": "d8f0b7c6-1519-49ec-fbc8-a560317f5c70"
      },
      "outputs": [],
      "source": [
        "# R2:\n",
        "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\",\n",
        "                                   labelCol=\"close\",\n",
        "                                   metricName=\"r2\")\n",
        " \n",
        "print(\"R2 on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQqpe5jwGW3v"
      },
      "outputs": [],
      "source": [
        "lr_model.write().overwrite().save(\"/content/drive/MyDrive/fo/models/predict/PKN.WA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNURr-lCLlFZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "01--postgresql.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
